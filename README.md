# Sign-language-detector-python
The focus was on creating a real-time computer vision system for recognizing American sign language without requiring special equipment. It
utilizes MobileNet for gesture recognition and achieved 92% accuracy by ensembling four models. The system includes a head pose estimationbased feedback unit and was developed using Python, OpenCV, and TensorFlow. It can be operated as a web application using Flask. There are plans
for further improvements, including deep learning-based hand detection and LSTM-based word/sentence auto-completion, to enhance accessibility
for the specially-abled community.
